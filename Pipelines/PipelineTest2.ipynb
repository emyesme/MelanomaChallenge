{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip setuptools wheel\n",
    "#!python -m pip install opencv-python\n",
    "#!pip install matplotlib\n",
    "#!pip freeze\n",
    "#!pip install opencv-python-headless\n",
    "#!pip install scikit-image\n",
    "#!pip install -U scikit-fuzzy\n",
    "#!pip install pandas\n",
    "#!pip install scikit-learn\n",
    "#!pip install tqdm==4.40.0\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from skimage import measure\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "import skfuzzy as fuzz\n",
    "import library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMAGE PROCESSING - PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bansal paper laplacian of gaussian + top hat morphology\n",
    "# NOT FINISHED!!!!!!\n",
    "def hairRemoval_LoG_THM(matrix, ksize = 3, kernel_size = 17, filterSize = (11, 11)):\n",
    "    # 1. grayscale\n",
    "    gray = cv2.cvtColor(matrix, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2. laplacian of gaussian\n",
    "    # steps are blurring,\n",
    "    #           laplacian,\n",
    "    #           zero_crossing,\n",
    "    #           threshold zero crossing to extract strong edges\n",
    "    ddepth = cv2.CV_16S\n",
    "    blur = cv2.GaussianBlur(gray, (ksize, ksize), 0)\n",
    "    lp = cv2.Laplacian(blur, ddepth, ksize=ksize)\n",
    "    # converting output back to uint8\n",
    "    log = cv2.convertScaleAbs(lp)\n",
    "\n",
    "    # 3. closing and dilation\n",
    "    kernel = cv2.getStructuringElement(1,(kernel_size,kernel_size))\n",
    "    close = cv2.morphologyEx(log, cv2.MORPH_CLOSE, kernel)\n",
    "    dil = cv2.dilate(close, kernel)\n",
    "    \n",
    "    # 4. top-hat transformation   \n",
    "    kernel_th = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, \n",
    "                                          filterSize)\n",
    "    \n",
    "    tophat = cv2.morphologyEx(dil, \n",
    "                              cv2.MORPH_TOPHAT,\n",
    "                              kernel_th)\n",
    "    # 5. otsu\n",
    "    #thresh = cv2.threshold(sharp, 0, 255, cv2.THRESH_OTSU )[1]\n",
    "    # 6. erosion and closing\n",
    "    # 7. impainting\n",
    "    \n",
    "    return log, close, dil, tophat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First pipeline with \n",
    "\n",
    "- hair removal\n",
    "- segmentation with kmeans\n",
    "- extracting asymmetry from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_DIR = \"/home/emily/Desktop/CAD/challenge1/train\"\n",
    "\n",
    "# img = cv2.imread(join(FOLDER_DIR,\"nevus\", \"nev{}.jpg\".format(\"03178\")))\n",
    "img = cv2.imread(join(FOLDER_DIR, \"others\", \"{}.jpg\".format(\"ack00322\")))\n",
    "# 00656 02056 01831 00547 02237  02462 02655  03178 03284   04438  05209 bcc00220 bcc00242\n",
    "# 04762 04176 cute\n",
    "# 00246 05464 02758 02462 02379 shity\n",
    "# 03863 finger\n",
    "# others ack00291 ack00363 bcc00001 bc00103 ack00028 ack00180 ack00322 bcc00221 bcc00271 bkl00160 ack00021\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "nevus = np.array(img_rgb)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('original')\n",
    "plt.show()\n",
    "\n",
    "output_bh = library.hair_removal_BH(img)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(output_bh, cv2.COLOR_BGR2RGB))\n",
    "plt.title('preprocessing blackhat')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mask = segmentation_kmeans(output_bh)\n",
    "\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title('mask')\n",
    "plt.show()\n",
    "\n",
    "asy = asymmetry(mask, False)\n",
    "print('asymmetry value: ', asy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURES EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABCD Rule\n",
    "\n",
    "commonly used feature extraction method from dermoscopic images is based on the ABCD rule of dermatoscopu nachbar et al 1994.  this method consider 4 criteria: \n",
    "\n",
    "- asymmetry: if you draw a like through the half of the mole and the halfs are different. its asymetrical\n",
    "- border structure\n",
    "- color variation\n",
    "- diameter of skin lesion.\n",
    "\n",
    "inspiration for code from\n",
    "\n",
    "https://github.com/sohum2002/melanoma-detection/blob/master/melanoma/feature_extraction/asymmetry_index.py\n",
    "https://github.com/hadikhanhk786/melanoma-detection-python/blob/master/src/Lesion.py\n",
    "https://github.com/RCharradi/Melanoma-detection-from-dermoscopy-images-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ASYMMETRY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/sohum2002/melanoma-detection/blob/master/melanoma/feature_extraction/asymmetry_index.py\n",
    "\n",
    "def checkOverlap(shape1, shape2):\n",
    "    #Find the accuracy of symmetry\n",
    "    all_pixels = 0.\n",
    "    correct = 0.\n",
    "    wrong = 0.\n",
    "\n",
    "    for i in range(shape1.shape[0]):\n",
    "        for j in range(shape1.shape[1]):\n",
    "\n",
    "            curr_pixel1 = (shape1[i][j])\n",
    "            curr_pixel2 = (shape2[i][j])\n",
    "\n",
    "            if(curr_pixel1 or curr_pixel2):\n",
    "                all_pixels += 1\n",
    "                if(curr_pixel1 and curr_pixel2):\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    wrong += 1\n",
    "\n",
    "    return correct, wrong, all_pixels\n",
    "\n",
    "def asymmetry(mask, flag):\n",
    "    \n",
    "    # 0. variables\n",
    "    x = []\n",
    "    y = []\n",
    "    top  = np.zeros((mask.shape[0], mask.shape[1]), dtype=bool)\n",
    "    left = np.zeros((mask.shape[0], mask.shape[1]), dtype=bool)\n",
    "    bottom = np.zeros((mask.shape[0], mask.shape[1]), dtype=bool)\n",
    "    right = np.zeros((mask.shape[0], mask.shape[1]), dtype=bool)\n",
    "    \n",
    "    # 1. find the center of the image\n",
    "    for i in range(mask.shape[0]):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if (mask[i][j] != 1):\n",
    "                x.append(j)\n",
    "                y.append(i)\n",
    "    \n",
    "    # centroid = ( gray.shape[0] / 2, gray.shape[1] / 2) # need to change if segmentation maskk\n",
    "    centroid = (sum(x) / len(x), sum(y) / len(y))\n",
    "    print('centroid ', centroid)\n",
    "    \n",
    "    # print(np.unique(mask))\n",
    "    \n",
    "    # 2. split top/down images\n",
    "    for i in range(mask.shape[0]):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if (mask[i][j] < 1):\n",
    "                if (i < centroid[1]):\n",
    "                    top[i][j] = True\n",
    "    if flag:\n",
    "        plt.imshow(top)\n",
    "        plt.title('top')\n",
    "        plt.show()\n",
    "    \n",
    "    # 4. split left/right images\n",
    "    for i in range(mask.shape[0]):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if (mask[i][j] < 0.95):\n",
    "                if (j < centroid[0]):\n",
    "                    left[i][j] = True\n",
    "    if flag:\n",
    "        plt.imshow(left)\n",
    "        plt.title('left')\n",
    "        plt.show()\n",
    "    \n",
    "    # doing for flip top/down images\n",
    "    flipped_ud = np.flipud(mask)\n",
    "    \n",
    "    for i in range(flipped_ud.shape[0]):\n",
    "        for j in range(flipped_ud.shape[1]):\n",
    "            if(flipped_ud[i][j] < 0.95):\n",
    "                if(i < centroid[1]):\n",
    "                    bottom[i][j] = True\n",
    "    \n",
    "    if flag:\n",
    "        plt.imshow(bottom)\n",
    "        plt.title('bottom')\n",
    "        plt.show()\n",
    "    \n",
    "    # doing for flip left/right to get the right part\n",
    "    flipped_lr = np.fliplr(mask)\n",
    "    \n",
    "    # performing splitting for top/down images\n",
    "    for i in range(flipped_lr.shape[0]):\n",
    "        for j in range(flipped_lr.shape[1]):\n",
    "            if(flipped_lr[i][j] < 0.95):\n",
    "                if(j < centroid[0]):\n",
    "                    right[i][j] = True\n",
    "    if flag:\n",
    "        plt.imshow(right)\n",
    "        plt.title('right')\n",
    "        plt.show()        \n",
    "        \n",
    "    correct_TB, wrong_TB, all_TB = checkOverlap(top, bottom)\n",
    "    correct_LR, wrong_LR, all_LR = checkOverlap(left, right)\n",
    "    \n",
    "    if flag:\n",
    "        print(correct_TB)\n",
    "        print(all_TB)\n",
    "        print(correct_LR)\n",
    "        print(all_LR)\n",
    "    \n",
    "    return 1- sum([correct_TB / all_TB, correct_LR / all_LR]) / 2\n",
    "\n",
    "result_asym = asymmetry(mask, True)\n",
    "\n",
    "print('symmetry ', result_asym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/25008458/how-to-apply-clahe-on-rgb-color-images\n",
    "def clahe_rgb(img, gridsize=100):\n",
    "\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    lab_planes = cv2.split(lab)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(gridsize,gridsize))\n",
    "\n",
    "    lab_planes = np.array([map(list, lab_planes)])\n",
    "    \n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "\n",
    "    lab = cv2.merge(lab_planes)\n",
    "\n",
    "    result = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import library\n",
    "import texture_features\n",
    "import color_features\n",
    "import glcm_features\n",
    "import hair_removal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "samples = library.get_sample(path = \"/home/emily/Desktop/CAD/challenge1/train\", amount=2)\n",
    "\n",
    "dictF = {}\n",
    "features = pd.DataFrame()\n",
    "count = 0\n",
    "flag = True\n",
    "\n",
    "for sample in samples:\n",
    "    print('count ', count)\n",
    "    count += 1\n",
    "    \n",
    "    # read image\n",
    "    img = cv2.imread(sample)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "\n",
    "    # clahe preprocessing\n",
    "    #clahe = clahe_rgb(img, 8)\n",
    "    \n",
    "    # gray world. color balanced\n",
    "    #prepro = library.grey_world(img)\n",
    "    prepro = img\n",
    "    \n",
    "    # hair removal\n",
    "    output_bh = hair_removal.hair_remove(prepro, 17, 4)\n",
    "    print(\"hairless\")\n",
    "    \n",
    "    dictF['name'] = sample\n",
    "    dictF['label'] = (0 if 'nevus' in sample else 1 )\n",
    "    \n",
    "    # color features\n",
    "    colors = color_features.extract_color_features(prepro)\n",
    "    dictF.update(colors)\n",
    "    \n",
    "    # glcm features\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    distances = [1]\n",
    "    colorspaces = ['rgb', 'hsv', 'lab', 'ycc', 'gray']\n",
    "    \n",
    "    for cs in colorspaces:\n",
    "        glcm = glcm_features.get_glcm(prepro, angles, distances, cs)\n",
    "        dictF.update(glcm)\n",
    "    \n",
    "    \n",
    "    # lbp features\n",
    "    lbp = texture_features.extract_lbp(prepro, 1, 8)\n",
    "    dictF.update(lbp)\n",
    "    \n",
    "    # orb features\n",
    "    # orb = texture_features.extract_orb(output_bh, 64)\n",
    "    # dictF.update(orb)\n",
    "    \n",
    "    features = features.append(dictF, ignore_index=True)\n",
    "    \n",
    "    # save features\n",
    "    library.writeFeatures(features,\n",
    "                  flag,\n",
    "                  os.path.join('/home',\n",
    "                             'emily',\n",
    "                             'Desktop',\n",
    "                             'CAD'),\n",
    "                  'features_prepro_shaver_4.csv')\n",
    "    \n",
    "    flag = False\n",
    "    features = pd.DataFrame()\n",
    "    dictF.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import library\n",
    "import mlxtend\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif    \n",
    "\n",
    "#\n",
    "classifiers = [\"svm\", \"adaboost\", \"gradboost\", \"histgradboost\", \"rf\", \"tree\",\"knn\", \"lda\"]\n",
    "\n",
    "train = pd.read_csv(os.path.join('/home','emily','Desktop','CAD','MelanomaChallenge','features','featuresCh1E.csv'))\n",
    "#test = pd.read_csv(os.path.join('/home','emily','Desktop','CAD','MelanomaChallenge','features','featuresCh1TestB.csv'))\n",
    "\n",
    "\n",
    "y = train['label']\n",
    "X = train.drop(['label'], axis=1)\n",
    "X = X.drop(['name'], axis=1)\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#y_test = test['label']\n",
    "#X_test = test.drop(['label'], axis=1)\n",
    "#X_test = X_test.drop(['name'], axis=1)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=42)\n",
    "\n",
    "# preprocessing options\n",
    "#('selectFromModel', SelectFromModel(RandomForestClassifier(random_state=42, n_jobs = -1)))\n",
    "#('selector rfe', RFE(RandomForestClassifier(random_state=42, n_jobs = -1))),\n",
    "#('reduce_dims', PCA(n_components=150)),\n",
    "#('mutual_info_classif, SelectKBest(mutual_info_classif, k=100)),\n",
    "\n",
    "\n",
    "sfs = SFS(estimator=RandomForestClassifier(random_state=42, n_jobs = -1),\n",
    "         k_features=3,\n",
    "         scoring='accuracy',\n",
    "         cv=5)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    \n",
    "    # preprocessing steps\n",
    "    pipe = [('scale', StandardScaler()),\n",
    "            #('pca', PCA(0.95)),\n",
    "            ('selector rfe', RFE(RandomForestClassifier(random_state=42, n_jobs = -1)))\n",
    "            #('sfs', sfs)\n",
    "            #('selectFromModel', SelectFromModel(RandomForestClassifier(random_state=42, n_jobs = -1)))\n",
    "           ]\n",
    "\n",
    "    \n",
    "    if classifier == \"svm\":\n",
    "        clf, best_params = library.SVC_linear(X_val, y_val, cv=2, best_params={'C': 1, 'gamma': 2.5, 'kernel': 'rbf'})\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### SVM ###\")\n",
    "    \n",
    "    elif classifier == \"rf\":\n",
    "        clf, best_params = library.RandomForest(X_val, y_val, cv=2, best_params={'criterion': 'gini', 'max_depth': 10, 'n_estimators': 100})\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### RF ###\")\n",
    "    \n",
    "    elif classifier == \"tree\":\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "        print(\"### TREE ###\")\n",
    "    \n",
    "    elif classifier == \"adaboost\":\n",
    "        clf, best_params = library.AdaBoost(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### ADABOOST ###\")\n",
    "    \n",
    "    elif classifier == \"gradboost\":\n",
    "        clf, best_params = library.GradientBoosting(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### GRADBOOST ###\")\n",
    "    \n",
    "    elif classifier == \"knn\":\n",
    "        clf, best_params = library.knn(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### KNN ###\")\n",
    "        \n",
    "    elif classifier == \"histgradboost\":\n",
    "        clf = HistGradientBoostingClassifier()\n",
    "        print(\"### HISTGRADBOOST ###\")\n",
    "        \n",
    "    elif classifier == \"lda\":\n",
    "        clf = LinearDiscriminantAnalysis()\n",
    "        print(\"### LDA ###\")        \n",
    "        \n",
    "    # add classifier \n",
    "    pipe.append(tuple(('clf', clf)))\n",
    "    \n",
    "    steps = Pipeline(pipe)\n",
    "    \n",
    "    # pipeline shape\n",
    "    print(\"current pipeline\")\n",
    "    print(steps)\n",
    "    \n",
    "    library.fit_report(steps, X, y, X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8303346cf061856616ea71480663e8efb94f012cfcc13615ad12237b3e78185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
