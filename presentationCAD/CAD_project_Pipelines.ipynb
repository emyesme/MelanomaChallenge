{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip setuptools wheel\n",
    "#!python -m pip install opencv-python\n",
    "#!pip install matplotlib\n",
    "#!pip freeze\n",
    "#!pip install opencv-python-headless\n",
    "#!pip install scikit-image\n",
    "#!pip install -U scikit-fuzzy\n",
    "#!pip install pandas\n",
    "#!pip install scikit-learn\n",
    "#!pip install xgboost\n",
    "#!pip install seaborn\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import library\n",
    "import numpy as np\n",
    "import hair_removal\n",
    "import pandas as pd\n",
    "import glcm_features\n",
    "import color_features\n",
    "import shape_features\n",
    "import texture_features\n",
    "from os.path import join\n",
    "from multiprocessing import Process\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_challenge = \"ch1\"\n",
    "pipeline = \"F\"\n",
    "\n",
    "def run_process(args):\n",
    "    flag = True\n",
    "    dictF = {}\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    idx = args[0]\n",
    "    samples = args[1]\n",
    "    current_challenge = args[2]\n",
    "    \n",
    "    for sample in samples:\n",
    "        \n",
    "        # pipeline call\n",
    "        #features = library.PipelineB(dictF, features, sample, current_challenge)\n",
    "        #features = library.PipelineC(dictF, features, sample, current_challenge)\n",
    "        #features = library.PipelineD(dictF, features, sample, current_challenge)\n",
    "        #features = library.PipelineE(dictF, features, sample, current_challenge)\n",
    "        #features = library.PipelineF(dictF, features, sample, current_challenge)\n",
    "        #features = library.PipelineG(dictF, features, sample, current_challenge)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # save features\n",
    "        library.writeFeatures(features,\n",
    "                      flag,\n",
    "                      os.path.join('/home',\n",
    "                         'emily',\n",
    "                         'Desktop',\n",
    "                         'CAD',\n",
    "                         'MelanomaChallenge',\n",
    "                         'features'),\n",
    "                         'features{}_{}_{}.csv'.format(current_challenge, pipeline, idx))\n",
    "        \n",
    "        flag = False\n",
    "        features = pd.DataFrame()\n",
    "        dictF.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processes = []\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "def create_batches(iterable, n = 1):\n",
    "    current_batch = []\n",
    "    for item in iterable:\n",
    "        current_batch.append(item)\n",
    "        if len(current_batch) == n:\n",
    "            yield current_batch\n",
    "            current_batch = []\n",
    "    if current_batch:\n",
    "        yield current_batch\n",
    "\n",
    "def prepare_process(samples):\n",
    "    # divide the samples into n=8 subsets\n",
    "    # the n value depend on the capability of the pc and the total quantity of samples\n",
    "    subsetsamples = np.array_split(samples, 8)#14800/8\n",
    "    for idx, subsetsample in enumerate(subsetsamples):\n",
    "        p = Process(target=run_process, args=([idx, subsetsample, current_challenge], ))\n",
    "        all_processes.append(p)\n",
    "    \n",
    "    for batch in create_batches(all_processes,BATCH_SIZE):\n",
    "        for process in batch:\n",
    "            process.start()\n",
    "        for process in batch:\n",
    "            process.join()\n",
    "\n",
    "flag = True\n",
    "output = \"\"\n",
    "\n",
    "# get a sample of the path\n",
    "allsamples, flag = library.get_sample(\"/home/emily/Desktop/CAD/challenge1/train\",output, flag, 14800)\n",
    "\n",
    "# get names belonging to already performed samples\n",
    "if os.path.exists(os.path.join('/home',\n",
    "                     'emily',\n",
    "                     'Desktop',\n",
    "                     'CAD',\n",
    "                     'MelanomaChallenge',\n",
    "                     'features',\n",
    "                     'features{}_{}.csv'.format(current_challenge, pipeline))):\n",
    "    donesamples = pd.read_csv(os.path.join('/home',\n",
    "                         'emily',\n",
    "                         'Desktop',\n",
    "                         'CAD',\n",
    "                         'MelanomaChallenge',\n",
    "                         'features',\n",
    "                         'features{}_{}.csv'.format(current_challenge, pipeline)))['name'].values.tolist()\n",
    "\n",
    "    # get names of missing samples\n",
    "    missingsamples = library.uniques_names(allsamples, donesamples)\n",
    "\n",
    "    # if want to perform the samples pending\n",
    "    prepare_process(missingsamples)\n",
    "else:\n",
    "    # if want to perform all the samples\n",
    "    prepare_process(allsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8303346cf061856616ea71480663e8efb94f012cfcc13615ad12237b3e78185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
