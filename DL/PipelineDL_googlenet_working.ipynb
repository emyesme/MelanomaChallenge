{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_9rhux8SW0Ts"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# import the required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.utils.data as data\n",
    "import copy\n",
    "\n",
    "from torchmetrics import F1Score\n",
    "from torchmetrics.functional import auroc\n",
    "from torchmetrics.functional import precision_recall\n",
    "from torchmetrics import AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u27ZtWK1XAY-"
   },
   "outputs": [],
   "source": [
    "#first put a shortcut in your drive to the image processing folder\n",
    "\n",
    "RESULTS_DIR = os.path.join('/home',\n",
    "                        'emily',\n",
    "                        'Desktop',\n",
    "                        'CAD',\n",
    "                        'results',\n",
    "                        'model')\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join('/home',\n",
    "                        'emily',\n",
    "                        'Desktop',\n",
    "                        'CAD',\n",
    "                        'challenge1')\n",
    "\n",
    "#print(os.listdir(RESULTS_DIR))\n",
    "\n",
    "data_file = os.listdir(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I0CzC_YGW1Yx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "momentum = 0.9\n",
    "lr_step_size = 7   # if < epochs, we are using decaying learning rate\n",
    "lr_gamma = 0.1\n",
    "data_augmentation = True\n",
    "dropout = 0.1\n",
    "activation = nn.LeakyReLU()\n",
    "\n",
    "# make visible only one GPU at the time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # <-- should be the ID of the GPU you want to use\n",
    "\n",
    "# options\n",
    "# device = \"cuda:0\"           # put here \"cuda:0\" if you want to run on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor_display = True      # whether to display monitored performance plots\n",
    "display_first_n = 0         # how many samples/batches are displayed\n",
    "num_workers = 2             # how many workers (=threads) for fetching data\n",
    "pretrained = False          # whether to test a pretrained model (to be loaded) or train a new one\n",
    "display_errors = True       # whether to display errors (only in pretrained mode)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YMoibauPrDjm"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "# We need to use numpy for rotation transformation\n",
    "# For sigma and mean we nee to do patch wise\n",
    "\n",
    "# https://arxiv.org/pdf/2010.05351v1.pdf\n",
    "class MyRotationTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, times, mode):\n",
    "        self.times = times\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mode = random.choice(self.mode)\n",
    "        if mode == 0:\n",
    "          return np.fliplr(x)\n",
    "        elif mode == 1:\n",
    "          return np.flipud(x)\n",
    "        else:   \n",
    "          times = random.choice(self.times)\n",
    "          return np.rot90(x, times)\n",
    "# -90, 0, 90, and 180 degrees rotation\n",
    "\n",
    "#rotation_transform = MyRotationTransform(angles=[-90, 0, 90, 180])\n",
    "# pytorch transformations for augmentation https://arxiv.org/pdf/2010.05351v1.pdf\n",
    "# DataAugmentation = transforms.RandomApply(\n",
    "#         [ np.RandomHorizontalFlip(), \n",
    "#      transforms.RandomVerticalFlip(),\n",
    "#      #transforms.RandomRotation(90, fill=(0,)),\n",
    "#       MyRotationTransform(times=[1,2,3])] , p=0.5)  # fill=(0,) is a workaround for the torchvision bug tracked at https://github.com/pytorch/vision/issues/1759#issuecomment-575307516\n",
    "\n",
    "class Convert(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.unsqueeze(torch.from_numpy(img.astype('float')), 0).float()\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [MyRotationTransform(times=[1,2,3], mode=[0,1,2,3])]) \n",
    "\n",
    "# should randomly apply a transformation from the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm8zZBDDYdjy"
   },
   "source": [
    "**Load information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}    \n",
    "\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "    \n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "val_labels =torch.Tensor([])\n",
    "for batch in dataloaders['val']:\n",
    "    val_labels = torch.cat((val_labels, batch[1]), 0)\n",
    "#print(val_labels)\n",
    "\n",
    "train_labels = torch.Tensor([])\n",
    "for batch in dataloaders['train']:\n",
    "    train_labels = torch.cat((train_labels, batch[1]), 0)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    #plt.figure(figsize = (6,6))\n",
    "    plt.imshow(inp)\n",
    "    #print(os.path.join(RESULTS_DIR, str(title[0])) + \".png\")\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, str(title)) + \".png\", dpi=300)\n",
    "    if title is not None:\n",
    "        plt.title(str(title))\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "batch = next(iter(dataloaders['train']))\n",
    "inputs = batch[0]\n",
    "classes = batch[1]\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "#imshow(out, title=[x.item() for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz8hf2H6uAaQ"
   },
   "source": [
    "**Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GM_jp5acK70y"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DDuCOfTYaKM"
   },
   "source": [
    "### **Model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ti68kRkObivY"
   },
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# pretrained efficient net b3\n",
    "# https://pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b3.html#torchvision.models.efficientnet_b3\n",
    "googlenet = models.googlenet(weights=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# https://stackoverflow.com/questions/68047331/how-to-add-the-last-classification-layer-in-efficienet-pre-trained-model-in-pyto\n",
    "# efficientnet._fc = torch.nn.Linear(in_features = efficientb3._fc.in_features,\n",
    "#                                   out_features = NUM_CLASSES,\n",
    "#                                   bias = TRUE)\n",
    "#print(googlenet)\n",
    "googlenet.fc = torch.nn.Linear( in_features = googlenet.fc.in_features,\n",
    "                                          out_features = NUM_CLASSES,\n",
    "                                          bias = True)\n",
    "#efficientb3.fc = nn.Linear(2048,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-foaC4XPd9A"
   },
   "source": [
    "**Useful Metrics and Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uB8A7rDS0EG5"
   },
   "outputs": [],
   "source": [
    "def confusion(prediction, truth):\n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_vector = prediction / truth\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Positive)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
    "    #   nan   where prediction and truth are 0 (True Negative)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
    "\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Qd_99B-tUrRV"
   },
   "outputs": [],
   "source": [
    "def save(model, path_to_save: str) -> None:\n",
    "    torch.save(model.state_dict(), path_to_save)\n",
    "\n",
    "def load(model, path_to_model: str):\n",
    "    return model.load_state_dict(torch.load(path_to_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train function (1 epoch)\n",
    "# returns average loss and accuracy\n",
    "def train(dataset_size, net, scheduler, device, optimizer, criterion, dataloader):\n",
    "\n",
    "    # switch to train mode\n",
    "    net.train()\n",
    "\n",
    "    # step learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # reset performance measures\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    # 1 epoch = 1 complete loop over the dataset\n",
    "    for batch in dataloader:\n",
    "\n",
    "        # get data from dataloader\n",
    "        inputs, targets = batch\n",
    "\n",
    "        # move data to device\n",
    "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # loss gradient backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # net parameters update\n",
    "        optimizer.step()\n",
    "\n",
    "        # accumulate loss\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        # accumulate correct outputs (for accuracy calculation)\n",
    "        outputs_max = outputs.argmax(dim=1)\n",
    "        correct += outputs_max.eq(targets).sum().float().item()\n",
    "\n",
    "    # return average loss and accuracy        \n",
    "    avg_loss = loss_sum / len(dataloader)\n",
    "    accuracy_train = 100. * correct / dataset_size\n",
    "    return avg_loss, accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test function\n",
    "# returns predictions\n",
    "def test(dataset_size, net, dataloader, criterion):\n",
    "\n",
    "    # switch to test mode\n",
    "    net.eval()  \n",
    "\n",
    "    # initialize predictions \n",
    "    predictions = torch.zeros(dataset_size, dtype=torch.int64)\n",
    "    sample_counter = 0\n",
    "\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    # do not accumulate gradients (faster)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # test all batches\n",
    "        for inputs, targets in dataloader:\n",
    "\n",
    "            # move data to device\n",
    "            inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # calculate loss\n",
    "            valid_loss = criterion(outputs, targets)\n",
    "            \n",
    "            # accumulate loss\n",
    "            loss_sum += valid_loss.item()\n",
    "            \n",
    "            # accumulate correct outputs (for accuracy calculation)\n",
    "            outputs_max = outputs.argmax(dim=1)\n",
    "            correct += outputs_max.eq(targets).sum().float().item()\n",
    "\n",
    "    # return average loss and accuracy        \n",
    "    avg_loss = loss_sum / len(dataloader)\n",
    "    accuracy_valid = 100. * correct / dataset_size\n",
    "    \n",
    "    return avg_loss, accuracy_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1pUh_a6PqMN"
   },
   "source": [
    "**Train and test function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yLRT9aFctJm9"
   },
   "outputs": [],
   "source": [
    "def train_model(model, val_labels, dataloader, criterion, optimizer, scheduler, model_name, num_epochs=30, load_trained=False):\n",
    "    \n",
    "    f1 = F1Score(num_classes=2).to(device)\n",
    "\n",
    "    if load_trained:\n",
    "      checkpoint = torch.load(os.path.join(RESULTS_DIR, model_name))\n",
    "      model.load_state_dict(checkpoint['model_state_dict'])\n",
    "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "      last_epoch = checkpoint['epoch']+1\n",
    "      loss = checkpoint['loss']\n",
    "\n",
    "    else:\n",
    "      last_epoch=0\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    ticks = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) #It keeps track of the parameters of the model in certain state\n",
    "    best_auc = 0.0\n",
    "  \n",
    "    for epoch in range(last_epoch, num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # measure time elapsed\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # start time\n",
    "        since = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss, accuracy_train = train(dataset_sizes['train'], net, scheduler, device, optimizer, criterion, dataloader['train'])\n",
    "        \n",
    "        # test on validation\n",
    "        # to check\n",
    "        valid_loss, accuracy_valid = test(dataset_sizes['val'], net, dataloader['val'], criterion)\n",
    "        \n",
    "        \n",
    "        # update performance historyw\n",
    "        train_losses.append(avg_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_accuracies.append(accuracy_train)\n",
    "        valid_accuracies.append(accuracy_valid)\n",
    "        ticks.append(epoch)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "    #            running_corrects = 0\n",
    "    \n",
    "        \n",
    "        print ( \"...TIME: {:.2f} seconds\\n\"\n",
    "                \"...train loss: {:.2f} (best {:.2f} at epoch {})\\n\"\n",
    "                \"...validation loss: {:.2f} (best {:.2f} at epoch {})\\n\"\n",
    "                \"...training accuracy: {:.2f} (best {:.2f} at epoch {})\\n\"\n",
    "                \"...validation accuracy: {:.2f} (best {:.2f} at epoch {})\".format(\n",
    "                time.time()-t0,\n",
    "                avg_loss, min(train_losses), ticks[np.argmin(train_losses)],\n",
    "                valid_loss, min(valid_losses), ticks[np.argmin(valid_loss)],\n",
    "                accuracy_train, max(train_accuracies), ticks[np.argmax(train_accuracies)],\n",
    "                accuracy_valid, max(valid_accuracies), ticks[np.argmax(valid_accuracies)]))\n",
    "\n",
    "        # plot\n",
    "        fig, ax1 = plt.subplots(figsize=(12,8), num=1)\n",
    "        ax1.set_xticks(np.arange(0, epochs+1, step=epochs/10.0))\n",
    "        ax1.set_xlabel('Epochs')\n",
    "        ax1.set_ylabel(type(criterion).__name__, color='blue')\n",
    "        ax1.set_ylim(0.0001, 10)\n",
    "        ax1.tick_params(axis='y', labelcolor='blue')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(ticks, train_losses, 'b-', linewidth=1.0, aa=True, \n",
    "            label='Training {:.2f} ( best {:.2f} at ep. {})'.format(avg_loss, min(train_losses), ticks[np.argmin(train_losses)]))\n",
    "        ax1.plot(ticks, valid_losses, 'b--', linewidth=1.0, aa=True,\n",
    "                 label='Validation {:.2f} ( best {:.2f} at ep. {})'.format(valid_loss, min(valid_losses), ticks[np.argmin(valid_losses)]))\n",
    "        ax1.legend(loc=\"lower left\")\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('Accuracy %', color='red')\n",
    "        ax2.set_ylim(50, 100)\n",
    "        ax2.set_yticks(np.arange(50, 100, step=10))\n",
    "        ax2.tick_params(axis='y', labelcolor='red')\n",
    "        ax2.plot(ticks, train_accuracies, 'r-', linewidth=1.0, aa=True, \n",
    "            label='Training {:.2f}%  ( best {:.2f}% at ep. {})'.format(accuracy_train, max(train_accuracies), ticks[np.argmax(train_accuracies)]))\n",
    "        ax2.plot(ticks, valid_accuracies, 'r--', linewidth=1.0, aa=True, \n",
    "            label='Validation {:.2f}% ( best {:.2f}% at ep. {})'.format(accuracy_valid, max(valid_accuracies), ticks[np.argmax(valid_accuracies)]))\n",
    "        ax2.legend(loc=\"lower right\")\n",
    "        plt.xlim(0, epochs+1)\n",
    "        # this works if running from notebooks\n",
    "        if True:\n",
    "            fig.show()\n",
    "            fig.canvas.draw()\n",
    "        # this works if running from console\n",
    "        else:\n",
    "            plt.draw()\n",
    "            plt.pause(0.001)\n",
    "        plt.savefig(os.path.join(RESULTS_DIR, experiment_ID) + \".png\", dpi=300)\n",
    "        fig.clear()\n",
    "\n",
    "\n",
    "        # deep copy the model if the performance improve\n",
    "        #if phase == 'val' and epoch_auc > best_auc:\n",
    "        #    best_auc = epoch_auc\n",
    "        #    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if (epoch-1) == np.argmax(valid_accuracies):\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "            }, os.path.join(RESULTS_DIR, model_name))  \n",
    "            \n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val auc: {:4f}'.format(best_auc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbWX0kP4Qhrw"
   },
   "source": [
    "**Model initialization and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Emo3pdAQIPe6"
   },
   "outputs": [],
   "source": [
    "net = googlenet.to(device) #we need to also send the model to the GPU as well\n",
    "\n",
    "# create loss function\n",
    "criterion = nn.CrossEntropyLoss() #most used for classification purposes\n",
    "\n",
    "# create SGD optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum) #most common optimizer is adam\n",
    "\n",
    "# create learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
    "\n",
    "# experiment ID\n",
    "experiment_ID = \"try_%s_%s_%s_bs(%d)lr(%.4f_%d_%.1f)m(%.1f)e(%d)act(%s)xavier(yes)da(%s)do(%.1f)BN\" % (type(net).__name__, type(criterion).__name__, type(optimizer).__name__,\n",
    "                batch_size, learning_rate, lr_step_size, lr_gamma, momentum, epochs, type(activation).__name__, data_augmentation, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SugDntlJSAgh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emily/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...TIME: 94.72 seconds\n",
      "...train loss: 0.51 (best 0.51 at epoch 0)\n",
      "...validation loss: 0.44 (best 0.44 at epoch 0)\n",
      "...training accuracy: 75.24 (best 75.24 at epoch 0)\n",
      "...validation accuracy: 79.61 (best 79.61 at epoch 0)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"1199.9166666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "...TIME: 92.83 seconds\n",
      "...train loss: 0.48 (best 0.48 at epoch 1)\n",
      "...validation loss: 0.38 (best 0.38 at epoch 0)\n",
      "...training accuracy: 77.62 (best 77.62 at epoch 1)\n",
      "...validation accuracy: 83.83 (best 83.83 at epoch 1)\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "...TIME: 94.85 seconds\n",
      "...train loss: 0.45 (best 0.45 at epoch 2)\n",
      "...validation loss: 0.36 (best 0.36 at epoch 0)\n",
      "...training accuracy: 79.22 (best 79.22 at epoch 2)\n",
      "...validation accuracy: 84.25 (best 84.25 at epoch 2)\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "...TIME: 92.93 seconds\n",
      "...train loss: 0.42 (best 0.42 at epoch 3)\n",
      "...validation loss: 0.37 (best 0.36 at epoch 0)\n",
      "...training accuracy: 80.97 (best 80.97 at epoch 3)\n",
      "...validation accuracy: 83.72 (best 84.25 at epoch 2)\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "...TIME: 92.90 seconds\n",
      "...train loss: 0.40 (best 0.40 at epoch 4)\n",
      "...validation loss: 0.37 (best 0.36 at epoch 0)\n",
      "...training accuracy: 81.70 (best 81.70 at epoch 4)\n",
      "...validation accuracy: 83.83 (best 84.25 at epoch 2)\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "...TIME: 94.66 seconds\n",
      "...train loss: 0.37 (best 0.37 at epoch 5)\n",
      "...validation loss: 0.35 (best 0.35 at epoch 0)\n",
      "...training accuracy: 83.23 (best 83.23 at epoch 5)\n",
      "...validation accuracy: 84.69 (best 84.69 at epoch 5)\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "...TIME: 90.85 seconds\n",
      "...train loss: 0.36 (best 0.36 at epoch 6)\n",
      "...validation loss: 0.34 (best 0.34 at epoch 0)\n",
      "...training accuracy: 83.86 (best 83.86 at epoch 6)\n",
      "...validation accuracy: 85.62 (best 85.62 at epoch 6)\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "...TIME: 92.62 seconds\n",
      "...train loss: 0.35 (best 0.35 at epoch 7)\n",
      "...validation loss: 0.33 (best 0.33 at epoch 0)\n",
      "...training accuracy: 84.22 (best 84.22 at epoch 7)\n",
      "...validation accuracy: 85.77 (best 85.77 at epoch 7)\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "...TIME: 93.06 seconds\n",
      "...train loss: 0.35 (best 0.35 at epoch 8)\n",
      "...validation loss: 0.33 (best 0.33 at epoch 0)\n",
      "...training accuracy: 84.42 (best 84.42 at epoch 8)\n",
      "...validation accuracy: 86.09 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "...TIME: 93.21 seconds\n",
      "...train loss: 0.35 (best 0.35 at epoch 9)\n",
      "...validation loss: 0.34 (best 0.33 at epoch 0)\n",
      "...training accuracy: 84.24 (best 84.42 at epoch 8)\n",
      "...validation accuracy: 85.62 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "...TIME: 92.86 seconds\n",
      "...train loss: 0.33 (best 0.33 at epoch 10)\n",
      "...validation loss: 0.35 (best 0.33 at epoch 0)\n",
      "...training accuracy: 85.26 (best 85.26 at epoch 10)\n",
      "...validation accuracy: 85.56 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "...TIME: 93.02 seconds\n",
      "...train loss: 0.34 (best 0.33 at epoch 10)\n",
      "...validation loss: 0.34 (best 0.33 at epoch 0)\n",
      "...training accuracy: 85.09 (best 85.26 at epoch 10)\n",
      "...validation accuracy: 85.75 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "...TIME: 93.45 seconds\n",
      "...train loss: 0.34 (best 0.33 at epoch 10)\n",
      "...validation loss: 0.34 (best 0.33 at epoch 0)\n",
      "...training accuracy: 84.63 (best 85.26 at epoch 10)\n",
      "...validation accuracy: 85.38 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "...TIME: 92.79 seconds\n",
      "...train loss: 0.34 (best 0.33 at epoch 10)\n",
      "...validation loss: 0.35 (best 0.33 at epoch 0)\n",
      "...training accuracy: 84.90 (best 85.26 at epoch 10)\n",
      "...validation accuracy: 84.80 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "...TIME: 92.69 seconds\n",
      "...train loss: 0.34 (best 0.33 at epoch 10)\n",
      "...validation loss: 0.33 (best 0.33 at epoch 0)\n",
      "...training accuracy: 85.14 (best 85.26 at epoch 10)\n",
      "...validation accuracy: 85.99 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "...TIME: 92.68 seconds\n",
      "...train loss: 0.33 (best 0.33 at epoch 10)\n",
      "...validation loss: 0.34 (best 0.33 at epoch 0)\n",
      "...training accuracy: 85.19 (best 85.26 at epoch 10)\n",
      "...validation accuracy: 85.46 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "...TIME: 92.59 seconds\n",
      "...train loss: 0.33 (best 0.33 at epoch 16)\n",
      "...validation loss: 0.34 (best 0.33 at epoch 0)\n",
      "...training accuracy: 85.47 (best 85.47 at epoch 16)\n",
      "...validation accuracy: 85.38 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "...TIME: 92.31 seconds\n",
      "...train loss: 0.34 (best 0.33 at epoch 16)\n",
      "...validation loss: 0.32 (best 0.32 at epoch 0)\n",
      "...training accuracy: 85.33 (best 85.47 at epoch 16)\n",
      "...validation accuracy: 85.96 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "...TIME: 92.58 seconds\n",
      "...train loss: 0.33 (best 0.33 at epoch 16)\n",
      "...validation loss: 0.33 (best 0.32 at epoch 0)\n",
      "...training accuracy: 84.94 (best 85.47 at epoch 16)\n",
      "...validation accuracy: 85.72 (best 86.09 at epoch 8)\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "...TIME: 93.35 seconds\n",
      "...train loss: 0.33 (best 0.33 at epoch 19)\n",
      "...validation loss: 0.33 (best 0.32 at epoch 0)\n",
      "...training accuracy: 85.63 (best 85.63 at epoch 19)\n",
      "...validation accuracy: 85.70 (best 86.09 at epoch 8)\n",
      "\n",
      "Training complete in 1m 34s\n",
      "Best val auc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "model = train_model(net, val_labels, dataloaders, criterion, optimizer, scheduler, 'try_model_googlenet.pt', num_epochs=epochs, load_trained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Rf_vzbUBZA-P"
   },
   "outputs": [],
   "source": [
    "save(model, RESULTS_DIR+'/try_model_googlenet_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFBKnnwrTgaU"
   },
   "source": [
    "## **Model Testing**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
