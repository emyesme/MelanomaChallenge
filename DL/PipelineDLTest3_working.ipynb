{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u27ZtWK1XAY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "#first put a shortcut in your drive to the image processing folder\n",
    "\n",
    "RESULTS_DIR = os.path.join('/home',\n",
    "                        'emily',\n",
    "                        'Desktop',\n",
    "                        'CAD',\n",
    "                         'results' )\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join('/home',\n",
    "                        'emily',\n",
    "                        'Desktop',\n",
    "                        'CAD',\n",
    "                        'challenge1')\n",
    "\n",
    "print(os.listdir(RESULTS_DIR))\n",
    "\n",
    "data_file = os.listdir(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_9rhux8SW0Ts"
   },
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.utils.data as data\n",
    "import copy\n",
    "\n",
    "from torchmetrics import F1Score\n",
    "from torchmetrics.functional import auroc\n",
    "from torchmetrics.functional import precision_recall\n",
    "from torchmetrics import AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I0CzC_YGW1Yx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.02\n",
    "epochs = 30\n",
    "momentum = 0.1\n",
    "lr_step_size = 1000   # if < epochs, we are using decaying learning rate\n",
    "lr_gamma = 0.1\n",
    "data_augmentation = True\n",
    "dropout = 0.1\n",
    "activation = nn.LeakyReLU()\n",
    "\n",
    "# make visible only one GPU at the time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # <-- should be the ID of the GPU you want to use\n",
    "\n",
    "# options\n",
    "# device = \"cuda:0\"           # put here \"cuda:0\" if you want to run on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor_display = True      # whether to display monitored performance plots\n",
    "display_first_n = 0         # how many samples/batches are displayed\n",
    "num_workers = 2             # how many workers (=threads) for fetching data\n",
    "pretrained = False          # whether to test a pretrained model (to be loaded) or train a new one\n",
    "display_errors = True       # whether to display errors (only in pretrained mode)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YMoibauPrDjm"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "# We need to use numpy for rotation transformation\n",
    "# For sigma and mean we nee to do patch wise\n",
    "\n",
    "# https://arxiv.org/pdf/2010.05351v1.pdf\n",
    "class MyRotationTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, times, mode):\n",
    "        self.times = times\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mode = random.choice(self.mode)\n",
    "        if mode == 0:\n",
    "          return np.fliplr(x)\n",
    "        elif mode == 1:\n",
    "          return np.flipud(x)\n",
    "        else:   \n",
    "          times = random.choice(self.times)\n",
    "          return np.rot90(x, times)\n",
    "# -90, 0, 90, and 180 degrees rotation\n",
    "\n",
    "#rotation_transform = MyRotationTransform(angles=[-90, 0, 90, 180])\n",
    "# pytorch transformations for augmentation https://arxiv.org/pdf/2010.05351v1.pdf\n",
    "# DataAugmentation = transforms.RandomApply(\n",
    "#         [ np.RandomHorizontalFlip(), \n",
    "#      transforms.RandomVerticalFlip(),\n",
    "#      #transforms.RandomRotation(90, fill=(0,)),\n",
    "#       MyRotationTransform(times=[1,2,3])] , p=0.5)  # fill=(0,) is a workaround for the torchvision bug tracked at https://github.com/pytorch/vision/issues/1759#issuecomment-575307516\n",
    "\n",
    "class Convert(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.unsqueeze(torch.from_numpy(img.astype('float')), 0).float()\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [MyRotationTransform(times=[1,2,3], mode=[0,1,2,3])]) \n",
    "\n",
    "# should randomly apply a transformation from the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm8zZBDDYdjy"
   },
   "source": [
    "**Load information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Bd864xCEiZng"
   },
   "outputs": [],
   "source": [
    "# train_percentage = 0.6\n",
    "# test_percentage = 0.25\n",
    "\n",
    "# train_size = int(len(dataset)*train_percentage)\n",
    "# test_size = int(len(dataset)*test_percentage)\n",
    "\n",
    "# indices = list(range(len(dataset)))\n",
    "# np.random.shuffle(indices)\n",
    "# train_indices, test_indices, val_indices = indices[:train_size], indices[train_size:train_size+test_size], indices[train_size+test_size:]\n",
    "# train_features = data.SubsetRandomSampler(train_indices)\n",
    "# val_features = data.SubsetRandomSampler(val_indices)\n",
    "# test_features = data.SubsetRandomSampler(test_indices)\n",
    "\n",
    "# dataloader_train = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=train_features)\n",
    "# dataloader_val = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=val_features)\n",
    "# dataloader_test = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz8hf2H6uAaQ"
   },
   "source": [
    "**Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GM_jp5acK70y"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "#dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) \n",
    "#dataloader_val = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)  # what is pin memory true\n",
    "\n",
    "#dataloader = {'train': dataloader_train, 'eval': dataloader_val}\n",
    "#dataset_sizes = {'train': len(dataset_train), 'eval': len(dataset_validation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DDuCOfTYaKM"
   },
   "source": [
    "### **Model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ti68kRkObivY"
   },
   "outputs": [],
   "source": [
    "#from torchsummary import summary\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "# pretrained resnet 50\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# freezing the first 10 layers\n",
    "ct = 0\n",
    "# model.children() which returns layers.\n",
    "for child in resnet50.children():\n",
    " ct += 1\n",
    " if ct < 3:\n",
    "     for param in child.parameters():\n",
    "      # True means it will be backpropagrated\n",
    "      # to freeze a layer you need to set requires_grad to False for all parameters of a layer. \n",
    "       param.requires_grad = False\n",
    "\n",
    "# change last fully convolutional layer so it returns just 2 classes\n",
    "resnet50.fc = nn.Linear(2048,2)\n",
    "\n",
    "# This part is to check the parameters of my network and the numbers to come\n",
    "\n",
    "# net = CD_CNN()\n",
    "# summary(net, (1,12,12))\n",
    "\n",
    "# dummy_variable = torch.rand(1,1,12,12) #batch size, channel, image size\n",
    "# net(dummy_variable).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-foaC4XPd9A"
   },
   "source": [
    "**Useful Metrics and Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uB8A7rDS0EG5"
   },
   "outputs": [],
   "source": [
    "def confusion(prediction, truth):\n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_vector = prediction / truth\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Positive)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
    "    #   nan   where prediction and truth are 0 (True Negative)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
    "\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Qd_99B-tUrRV"
   },
   "outputs": [],
   "source": [
    "def save(model, path_to_save: str) -> None:\n",
    "    torch.save(model.state_dict(), path_to_save)\n",
    "\n",
    "def load(model, path_to_model: str):\n",
    "    return model.load_state_dict(torch.load(path_to_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1pUh_a6PqMN"
   },
   "source": [
    "**Train and test function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yLRT9aFctJm9"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, scheduler, model_name, num_epochs=30, load_trained=False):\n",
    "    since = time.time()\n",
    "    f1 = F1Score(num_classes=2).to(device)\n",
    "\n",
    "    if load_trained:\n",
    "      checkpoint = torch.load(RESULTS_DIR + model_name)\n",
    "      model.load_state_dict(checkpoint['model_state_dict'])\n",
    "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "      last_epoch = checkpoint['epoch']+1\n",
    "      loss = checkpoint['loss']\n",
    "\n",
    "    else:\n",
    "      last_epoch=0\n",
    "\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) #It keeps track of the parameters of the model in certain state\n",
    "    best_auc = 0.0\n",
    "  \n",
    "    for epoch in range(last_epoch, num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "          \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "    #            running_corrects = 0\n",
    "            f1_history = list()\n",
    "\n",
    "            y_true = list()\n",
    "            y_pred = list()\n",
    "\n",
    "\n",
    "            tp_total = 0\n",
    "            fp_total = 0\n",
    "            tn_total = 0\n",
    "            fn_total = 0 \n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "    #                running_corrects += torch.sum(preds == labels.data)\n",
    "                f1_history.append(f1(preds, labels.data).double().cpu().numpy()) \n",
    "                y_true.append(labels.data.cpu())\n",
    "                sig = nn.Sigmoid()\n",
    "                y_pred.append(sig(outputs)[:,0].detach().cpu())\n",
    "    #                running_prerec += precision_recall(preds, labels.data)\n",
    "\n",
    "                tp, fp, tn, fn = confusion(preds, labels.data)\n",
    "                tp_total += tp\n",
    "                fp_total += fp\n",
    "                tn_total += tn\n",
    "                fn_total += fn\n",
    "    #                print(tp, fp, tn, fn) \n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_f1 = np.mean(f1_history)\n",
    "            epoch_auc = auroc(torch.cat(y_pred, dim=0), torch.cat(y_true, dim=0), max_fpr=0.0001).item()\n",
    "            # epoch_mcc = mcc(tp_total, fp_total, tn_total, fn_total)\n",
    "\n",
    "            if phase == 'train':\n",
    "              scheduler.step()\n",
    "              torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                }, RESULTS_DIR+ model_name)  \n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} F1-score: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_f1))\n",
    "            #print('MCC: ', epoch_mcc)\n",
    "            print('AUC: ', epoch_auc)                        \n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_auc > best_auc:\n",
    "                best_auc = epoch_auc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            del f1_history, y_true, y_pred\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val auc: {:4f}'.format(best_auc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "OnYAcElltZhk"
   },
   "outputs": [],
   "source": [
    "# define test function\n",
    "# returns predictions\n",
    "def test(dataset, dataloader):\n",
    "\n",
    "    # switch to test mode\n",
    "    net.eval()  \n",
    "\n",
    "    # initialize predictions\n",
    "    predictions = []\n",
    "    reals = [] #torch.zeros(len(dataset), dtype=torch.int64)\n",
    "    sample_counter = 0\n",
    "\n",
    "    # do not accumulate gradients (faster)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # test all batches\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            # get data from dataloader [ignore labels/targets as they are not used in test mode]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward pass\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # store predictions\n",
    "            outputs_max = torch.argmax(outputs, dim=1)\n",
    "            predictions.append( outputs_max)\n",
    "            reals.append(labels.data)\n",
    "            sample_counter += 1 #We should look for MCC, AUC or F1-score, p-AUC- Ratio of positive negatives 10 - 4, 10-3\n",
    "\n",
    "                #90 degrees rotations 1-100, 1-10\n",
    "\n",
    "                #patch wise output into a set of regions\n",
    "                #Using threshold\n",
    "                #output probability map image processing\n",
    "\n",
    "    return predictions, reals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbWX0kP4Qhrw"
   },
   "source": [
    "**Model initialization and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Emo3pdAQIPe6"
   },
   "outputs": [],
   "source": [
    "net = resnet50.to(device) #we need to also send the model to the GPU as well\n",
    "\n",
    "# create loss function\n",
    "criterion = nn.CrossEntropyLoss() #most used for classification purposes\n",
    "\n",
    "# create SGD optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum) #most common optimizer is adam\n",
    "\n",
    "# create learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
    "\n",
    "# experiment ID\n",
    "experiment_ID = \"%s_%s_%s_bs(%d)lr(%.4f_%d_%.1f)m(%.1f)e(%d)act(%s)xavier(yes)da(%s)do(%.1f)BN\" % (type(net).__name__, type(criterion).__name__, type(optimizer).__name__,\n",
    "                batch_size, learning_rate, lr_step_size, lr_gamma, momentum, epochs, type(activation).__name__, data_augmentation, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SugDntlJSAgh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "----------\n",
      "train Loss: 0.4129 F1-score: 0.8093\n",
      "AUC:  0.4999749958515167\n",
      "val Loss: 0.4360 F1-score: 0.8089\n",
      "AUC:  0.4999749958515167\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "train Loss: 0.3849 F1-score: 0.8286\n",
      "AUC:  0.4999749958515167\n",
      "val Loss: 0.3430 F1-score: 0.8453\n",
      "AUC:  0.4999749958515167\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "train Loss: 0.3565 F1-score: 0.8384\n",
      "AUC:  0.4999749958515167\n",
      "val Loss: 0.3893 F1-score: 0.8397\n",
      "AUC:  0.5002431273460388\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "train Loss: 0.3438 F1-score: 0.8476\n",
      "AUC:  0.4999749958515167\n",
      "val Loss: 0.3145 F1-score: 0.8632\n",
      "AUC:  0.4999749958515167\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model = train_model(net, dataloaders, criterion, optimizer, scheduler, '/model_resnet50.pt', num_epochs=epochs, load_trained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rf_vzbUBZA-P"
   },
   "outputs": [],
   "source": [
    "save(model, RESULTS_DIR+'/model_try1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFBKnnwrTgaU"
   },
   "source": [
    "## **Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affine==2.3.1\n",
      "appdirs==1.4.4\n",
      "apturl==0.5.2\n",
      "argon2-cffi==21.1.0\n",
      "attrs==21.2.0\n",
      "Babel==2.8.0\n",
      "backcall==0.2.0\n",
      "bcrypt==3.2.0\n",
      "beautifulsoup4==4.10.0\n",
      "beniget==0.4.1\n",
      "bleach==4.1.0\n",
      "blinker==1.4\n",
      "Brlapi==0.8.3\n",
      "Brotli==1.0.9\n",
      "caffeine==2.9.8\n",
      "certifi==2020.6.20\n",
      "chardet==4.0.0\n",
      "click==8.0.3\n",
      "click-plugins==1.1.1\n",
      "cligj==0.7.2\n",
      "colorama==0.4.4\n",
      "command-not-found==0.3\n",
      "cryptography==3.4.8\n",
      "cupshelpers==1.0\n",
      "cycler==0.11.0\n",
      "dbus-python==1.2.18\n",
      "decorator==4.4.2\n",
      "defer==1.0.6\n",
      "defusedxml==0.7.1\n",
      "distro==1.7.0\n",
      "distro-info===1.1build1\n",
      "duplicity==0.8.21\n",
      "entrypoints==0.4\n",
      "ewmh==0.1.6\n",
      "fasteners==0.14.1\n",
      "fonttools==4.29.1\n",
      "fs==2.4.12\n",
      "future==0.18.2\n",
      "gast==0.5.2\n",
      "html5lib==1.1\n",
      "httplib2==0.20.2\n",
      "idna==3.3\n",
      "imageio==2.22.0\n",
      "imbalanced-learn==0.9.1\n",
      "imblearn==0.0\n",
      "importlib-metadata==4.6.4\n",
      "intensity-normalization==2.2.3\n",
      "ipykernel==6.7.0\n",
      "ipython==7.31.1\n",
      "ipython_genutils==0.2.0\n",
      "ipywidgets==6.0.0\n",
      "jedi==0.18.0\n",
      "jeepney==0.7.1\n",
      "Jinja2==3.0.3\n",
      "joblib==1.2.0\n",
      "jsonschema==3.2.0\n",
      "jupyter-client==7.1.2\n",
      "jupyter-core==4.9.1\n",
      "jupyterlab-pygments==0.1.2\n",
      "keyring==23.5.0\n",
      "kiwisolver==1.3.2\n",
      "language-selector==0.1\n",
      "launchpadlib==1.10.16\n",
      "lazr.restfulclient==0.14.4\n",
      "lazr.uri==1.0.6\n",
      "libvirt-python==8.0.0\n",
      "lockfile==0.12.2\n",
      "louis==3.20.0\n",
      "lxml==4.8.0\n",
      "lz4==3.1.3+dfsg\n",
      "macaroonbakery==1.3.1\n",
      "mahotas==1.4.13\n",
      "Mako==1.1.3\n",
      "MarkupSafe==2.0.1\n",
      "matplotlib==3.5.1\n",
      "matplotlib-inline==0.1.3\n",
      "mlxtend==0.21.0\n",
      "monotonic==1.6\n",
      "more-itertools==8.10.0\n",
      "mpmath==0.0.0\n",
      "nb-clean==2.3.0\n",
      "nbclient==0.5.6\n",
      "nbconvert==6.4.0\n",
      "nbformat==5.1.3\n",
      "nest-asyncio==1.5.4\n",
      "netifaces==0.11.0\n",
      "networkx==2.8.6\n",
      "nibabel==4.0.2\n",
      "notebook==6.4.8\n",
      "numpy==1.23.4\n",
      "nvidia-cublas-cu11==11.10.3.66\n",
      "nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "nvidia-cuda-runtime-cu11==11.7.99\n",
      "nvidia-cudnn-cu11==8.5.0.96\n",
      "oauthlib==3.2.0\n",
      "olefile==0.46\n",
      "opencv-contrib-python==4.6.0.66\n",
      "opencv-python==4.6.0.66\n",
      "opencv-python-headless==4.6.0.66\n",
      "packaging==21.3\n",
      "pandas==1.5.0\n",
      "pandocfilters==1.5.0\n",
      "paramiko==2.9.3\n",
      "parso==0.8.1\n",
      "patsy==0.5.3\n",
      "pexpect==4.8.0\n",
      "phasepack==1.5\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.0.1\n",
      "ply==3.11\n",
      "prometheus-client==0.9.0\n",
      "prompt-toolkit==3.0.28\n",
      "protobuf==3.12.4\n",
      "ptyprocess==0.7.0\n",
      "py==1.10.0\n",
      "pycairo==1.20.1\n",
      "pycryptodomex==3.11.0\n",
      "pycups==2.0.1\n",
      "pydicom==2.3.0\n",
      "pyFFTW==0.13.0\n",
      "Pygments==2.11.2\n",
      "PyGObject==3.42.1\n",
      "PyJWT==2.3.0\n",
      "pymacaroons==0.13.0\n",
      "pymedio==0.2.13\n",
      "PyNaCl==1.5.0\n",
      "pyparsing==2.4.7\n",
      "pyRFC3339==1.1\n",
      "pyrsistent==0.18.1\n",
      "python-apt==2.3.0+ubuntu2.1\n",
      "python-dateutil==2.8.1\n",
      "python-debian===0.1.43ubuntu1\n",
      "python-xlib==0.29\n",
      "pythran==0.10.0\n",
      "pytz==2022.1\n",
      "PyWavelets==1.4.1\n",
      "pyxattr==0.7.2\n",
      "pyxdg==0.27\n",
      "PyYAML==5.4.1\n",
      "pyzmq==22.3.0\n",
      "rasterio==1.3.3\n",
      "reportlab==3.6.8\n",
      "requests==2.25.1\n",
      "scikit-fuzzy==0.4.2\n",
      "scikit-image==0.19.3\n",
      "scikit-learn==1.1.2\n",
      "scipy==1.8.0\n",
      "screen-resolution-extra==0.0.0\n",
      "seaborn==0.12.1\n",
      "SecretStorage==3.3.1\n",
      "Send2Trash==1.8.1b0\n",
      "SimpleITK==2.2.0\n",
      "six==1.16.0\n",
      "snuggs==1.4.7\n",
      "soupsieve==2.3.1\n",
      "statsmodels==0.13.2\n",
      "sympy==1.9\n",
      "systemd-python==234\n",
      "terminado==0.13.1\n",
      "testpath==0.5.0\n",
      "threadpoolctl==3.1.0\n",
      "tifffile==2022.8.12\n",
      "torch==1.13.0\n",
      "torchmetrics==0.10.3\n",
      "torchvision==0.14.0\n",
      "tornado==6.1\n",
      "tqdm==4.40.0\n",
      "traitlets==5.1.1\n",
      "typing_extensions==4.4.0\n",
      "ubuntu-advantage-tools==27.11.3\n",
      "ubuntu-drivers-common==0.0.0\n",
      "ufoLib2==0.13.1\n",
      "ufw==0.36.1\n",
      "unattended-upgrades==0.1\n",
      "unicodedata2==14.0.0\n",
      "urllib3==1.26.5\n",
      "usb-creator==0.3.7\n",
      "vboxapi==1.0\n",
      "wadllib==1.3.6\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "widgetsnbextension==2.0.0\n",
      "xdg==5\n",
      "xgboost==1.7.1\n",
      "xkit==0.0.0\n",
      "youtube-dl==2021.12.17\n",
      "zipp==1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
