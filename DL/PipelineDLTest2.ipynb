{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/emyesme/CalcificationDetection/blob/feature-pm/DeepLearning_MC_project_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import library\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from os.path import join\n",
    "import torch.optim as optim\n",
    "from torchmetrics import AUROC\n",
    "import torch.utils.data as data\n",
    "from torchmetrics import F1Score\n",
    "import torchvision.datasets as datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from torchmetrics.functional import auroc\n",
    "import torchvision.transforms as transforms\n",
    "from torchmetrics.functional import precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u27ZtWK1XAY-",
    "outputId": "aedd82b8-46aa-4f37-b50b-4fa07ce25d27"
   },
   "outputs": [],
   "source": [
    "RESULTS_DIR = os.path.join('/home',\n",
    "                            'emily',\n",
    "                            'Desktop',\n",
    "                            'CAD',\n",
    "                            'results')\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join('/home',\n",
    "                        'emily',\n",
    "                        'Desktop',\n",
    "                        'CAD',\n",
    "                        'challenge1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "I0CzC_YGW1Yx"
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 30\n",
    "momentum = 0.9\n",
    "lr_step_size = 6   # if < epochs, we are using decaying learning rate\n",
    "lr_gamma = 0.1\n",
    "data_augmentation = True\n",
    "dropout = 0.5\n",
    "activation = nn.ReLU()\n",
    "\n",
    "# make visible only one GPU at the time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # <-- should be the ID of the GPU you want to use\n",
    "\n",
    "# options\n",
    "# device = \"cuda:0\"           # put here \"cuda:0\" if you want to run on GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor_display = True      # whether to display monitored performance plots\n",
    "display_first_n = 0         # how many samples/batches are displayed\n",
    "num_workers = 2             # how many workers (=threads) for fetching data\n",
    "pretrained = False          # whether to test a pretrained model (to be loaded) or train a new one\n",
    "display_errors = True       # whether to display errors (only in pretrained mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YMoibauPrDjm"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "# We need to use numpy for rotation transformation\n",
    "# For sigma and mean we nee to do patch wise\n",
    "\n",
    "\n",
    "class MyTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, times, mode):\n",
    "        self.times = times\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mode = random.choice(self.mode)\n",
    "        if mode == 0:\n",
    "          return np.fliplr(x)\n",
    "        elif mode == 1:\n",
    "          return np.flipud(x)\n",
    "        else:   \n",
    "          times = random.choice(self.times)\n",
    "          return np.rot90(x, times)\n",
    "# -90, 0, 90, and 180 degrees rotation\n",
    "\n",
    "#rotation_transform = MyRotationTransform(angles=[-90, 0, 90, 180])\n",
    "\n",
    "# DataAugmentation = transforms.RandomApply(\n",
    "#         [ np.RandomHorizontalFlip(), \n",
    "#      transforms.RandomVerticalFlip(),\n",
    "#      #transforms.RandomRotation(90, fill=(0,)),\n",
    "#       MyRotationTransform(times=[1,2,3])] , p=0.5)  # fill=(0,) is a workaround for the torchvision bug tracked at https://github.com/pytorch/vision/issues/1759#issuecomment-575307516\n",
    "\n",
    "class Convert(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.unsqueeze(torch.from_numpy(img.astype('float')), 0).float()\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [MyTransform(times=[1,2,3], mode=[0,1,2,3])]) \n",
    "\n",
    "# should randomly apply a transformation from the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gm8zZBDDYdjy"
   },
   "source": [
    "**Load information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TSDpWbCcXc9o",
    "outputId": "1b2ccb92-a06b-4d70-b93b-8be51d4a1190"
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()#,\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()#,\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghoiFjYpzAWi",
    "outputId": "6fb9b86a-a9f3-4fef-a318-bd88f5924ca7"
   },
   "outputs": [],
   "source": [
    "dataset_train.class_total_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54ORzJinY3Fy"
   },
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1s5zPAAdxBro"
   },
   "outputs": [],
   "source": [
    "# train_size = int(0.8 * len(dataset_train))\n",
    "# validation_size = len(dataset_train) - train_size\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset_train, [train_size, validation_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bd864xCEiZng"
   },
   "outputs": [],
   "source": [
    "# train_percentage = 0.6\n",
    "# test_percentage = 0.25\n",
    "\n",
    "# train_size = int(len(dataset)*train_percentage)\n",
    "# test_size = int(len(dataset)*test_percentage)\n",
    "\n",
    "# indices = list(range(len(dataset)))\n",
    "# np.random.shuffle(indices)\n",
    "# train_indices, test_indices, val_indices = indices[:train_size], indices[train_size:train_size+test_size], indices[train_size+test_size:]\n",
    "# train_features = data.SubsetRandomSampler(train_indices)\n",
    "# val_features = data.SubsetRandomSampler(val_indices)\n",
    "# test_features = data.SubsetRandomSampler(test_indices)\n",
    "\n",
    "# dataloader_train = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=train_features)\n",
    "# dataloader_val = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=val_features)\n",
    "# dataloader_test = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXn10K9vBzjn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz8hf2H6uAaQ"
   },
   "source": [
    "**Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GM_jp5acK70y"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) \n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)  # what is pin memory true\n",
    "\n",
    "dataloader = {'train': dataloader_train, 'eval': dataloader_val}\n",
    "dataset_sizes = {'train': len(dataset_train), 'eval': len(dataset_validation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DDuCOfTYaKM"
   },
   "source": [
    "### **Model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0dWqccXXnAQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "class IncrementalBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(IncrementalBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.init_weigts()\n",
    "        \n",
    "    def init_weigts(self):\n",
    "        nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        self.conv1.bias.data.fill_(0.0)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        self.conv2.bias.data.fill_(0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ClassificationBlock(nn.Module):\n",
    "    def __init__(self, in_features=288):\n",
    "        super(ClassificationBlock, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=256)\n",
    "        self.out = nn.Linear(in_features=256, out_features=2)\n",
    "        self.init_weigts()\n",
    "        \n",
    "    def init_weigts(self):\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.fc1.bias.data.fill_(0.0)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        self.fc2.bias.data.fill_(0.0)\n",
    "        nn.init.xavier_uniform_(self.out.weight)\n",
    "        self.out.bias.data.fill_(0.0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.fc1(x))\n",
    "        x = F.dropout(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN_final(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN_final, self).__init__()\n",
    "        \n",
    "        self.num_ic = int(np.log2(input_size))-1\n",
    "        incremental_blocks = OrderedDict([])\n",
    "        for i in range(self.num_ic):\n",
    "            if i == 0:\n",
    "                in_channels = 1\n",
    "            else:\n",
    "                in_channels = 32\n",
    "            incremental_blocks.update({f\"IC{i}\": IncrementalBlock(in_channels)})\n",
    "        self.conv = nn.ModuleDict({\"incremental_block\": nn.Sequential(incremental_blocks)})\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = ClassificationBlock()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_ic):\n",
    "            x = self.conv.incremental_block[i](x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KHpATwIW29l"
   },
   "outputs": [],
   "source": [
    "# define CNN\n",
    "\n",
    "###\n",
    "# Haq, I.U., Ali, H., Yu, W.H., Lei, C., Ali, H., Feature fusion and ensemble learning\u0002based CNN model for mammographic image classification, Journal of King Saud University - Computer and\n",
    "# Information Sciences (2022), doi: https://doi.org/10.1016/j.jksuci.2022.03.023\n",
    "###\n",
    "\n",
    "## leakyrelu used instead of elu\n",
    "## Adam optimizer with a learning rate of 0.0001, β1 of 0.9, and β2 of 0.99, and a batch size of 24\n",
    "\n",
    "class CD_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CD_CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1) #kernel_size=7\n",
    "        # kernel sizes reduced due to patch size\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1) #kernel_size=7\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # stride? padding?\n",
    "        #https://stackoverflow.com/questions/63971920/why-am-i-getting-calculated-padding-input-size-per-channel-smaller-than-kernel-s\n",
    "        self.dropout1=nn.Dropout(p=0.2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        #self.dwconv1 = nn.DepthwiseConv2D(in_channels=64, out_channels=128, kernel_size=5, padding=1)\n",
    "        self.dwconv1 = nn.Conv2d(in_channels=64, out_channels=128, groups= 64, kernel_size=3, padding=1) #kernel_size=5\n",
    "        #https://discuss.pytorch.org/t/attributeerror-module-torch-nn-has-no-attribute-conv2d/90038\n",
    "        #https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html        \n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1) #kernel_size=5\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2=nn.Dropout(p=0.2)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "        #self.dwconv2 = nn.DepthwiseConv2D(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "       \n",
    "        # third block removed due to patch size\n",
    "        # self.dwconv2 = nn.Conv2d(in_channels=128, out_channels=256, groups= 128, kernel_size=3, padding=1)\n",
    "        # self.bn7 = nn.BatchNorm2d(256)\n",
    "        # self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        # self.bn8 = nn.BatchNorm2d(256)\n",
    "        # self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        # self.bn9 = nn.BatchNorm2d(256)\n",
    "        # self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # self.dropout3=nn.Dropout(p=0.2)\n",
    "        # self.bn10 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc1 = nn.Linear(128*3*3,512) #128*3*3 is output size of previous stage\n",
    "        self.fc2 = nn.Linear(512,2) # 2?\n",
    "\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "        \n",
    "        self.act = activation\n",
    "\n",
    "        #self.act = nn.Sigmoid()\n",
    "\n",
    "        nn.init.xavier_normal_(self.conv1.weight)\n",
    "        nn.init.xavier_normal_(self.conv2.weight)\n",
    "        nn.init.xavier_normal_(self.conv3.weight)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "       # nn.init.xavier_normal_(self.conv4.weight)\n",
    "       # nn.init.xavier_normal_(self.conv5.weight)\n",
    "        nn.init.xavier_normal_(self.dwconv1.weight)\n",
    "       # nn.init.xavier_normal_(self.dwconv2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.act(self.bn1(self.conv1(x)))\n",
    "        x = self.act(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn3(self.dropout1(x))\n",
    "        # print(x.size())\n",
    "\n",
    "        x = self.act(self.bn4(self.dwconv1(x)))\n",
    "        x = self.act(self.bn5(self.conv3(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn6(self.dropout2(x))\n",
    "        # print(x.size())\n",
    "\n",
    "        # x = self.act(self.bn7(self.dwconv2(x)))\n",
    "        # x = self.act(self.bn8(self.conv4(x))) \n",
    "        # x = self.act(self.bn9(self.conv5(x))) \n",
    "        # x = self.pool3(x)\n",
    "        # x = self.bn10(self.dropout3(x))\n",
    "        # print(x.size())\n",
    "\n",
    "        x = x.view(-1, 128*3*3)\n",
    "        x = self.act(self.fc1(x))\n",
    "\n",
    "        # print(x.size())\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # no activation: \"remember in this case to not specify the activation in the last layer when you define the net!\"\n",
    "        # consider softmax/logsoftmax\n",
    "        \n",
    "        # print(x.size())\n",
    "        \n",
    "        x = self.out(x)\n",
    "\n",
    "        # print(x.size())\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dm0MhGYYI1TU"
   },
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "       super(DeepNet, self).__init__()\n",
    "       self.fc1 = nn.Linear(144, 100)\n",
    "       self.fc2 = nn.Linear(100, 100)\n",
    "       self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "       nn.init.xavier_normal_(self.fc1.weight)\n",
    "       nn.init.xavier_normal_(self.fc2.weight)\n",
    "       nn.init.xavier_normal_(self.fc3.weight)\n",
    "\n",
    "       self.bn1 = nn.BatchNorm1d(100)\n",
    "       self.bn2 = nn.BatchNorm1d(100)\n",
    "\n",
    "       self.act = activation\n",
    "\n",
    "       self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.act(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NA8pQj2raNKL"
   },
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "      super(CNN1, self).__init__()\n",
    "\n",
    "      # in_channels is number of channels (this is because we have a patch of 1 image)\n",
    "      # out_channels is number of filters or kernels given out by the convolution\n",
    "      # stride is a parameter (default is 1)\n",
    "      self.conv1 =  nn.Conv2d(in_channels=1, out_channels=64, kernel_size=2, padding=1)\n",
    "      self.bn1 = nn.BatchNorm2d(64)\n",
    "      self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2, padding=1)\n",
    "      self.bn2 = nn.BatchNorm2d(64)\n",
    "      self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "      self.dropout1=nn.Dropout(p=0.2)\n",
    "      self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "      self.flatten = nn.Flatten()\n",
    "\n",
    "      self.fc1 = nn.Linear(3136,512)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      nn.init.xavier_normal_(self.fc1.weight)\n",
    "      nn.init.xavier_normal_(self.fc2.weight)\n",
    "      nn.init.xavier_normal_(self.conv1.weight)\n",
    "      nn.init.xavier_normal_(self.conv2.weight)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "      x = self.conv1(x)\n",
    "      x = self.bn1(x)\n",
    "      x = self.conv2(x)\n",
    "      x = self.conv2(x)\n",
    "      x = self.pool1(x)\n",
    "      x = self.dropout1(x)\n",
    "      x = self.bn3(x)\n",
    "      x = self.flatten(x)\n",
    "      x = self.fc1(x)\n",
    "      x = activation(x)\n",
    "      x = self.fc2(x)\n",
    "\n",
    "      return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ti68kRkObivY"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# This part is to check the parameters of my network and the numbers to come\n",
    "\n",
    "# net = CD_CNN()\n",
    "# summary(net, (1,12,12))\n",
    "\n",
    "# dummy_variable = torch.rand(1,1,12,12) #batch size, channel, image size\n",
    "# net(dummy_variable).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-foaC4XPd9A"
   },
   "source": [
    "**Useful Metrics and Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uB8A7rDS0EG5"
   },
   "outputs": [],
   "source": [
    "def confusion(prediction, truth):\n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_vector = prediction / truth\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Positive)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
    "    #   nan   where prediction and truth are 0 (True Negative)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
    "\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyyszbtD02Pd"
   },
   "outputs": [],
   "source": [
    "def mcc(tp, fp, tn, fn):\n",
    "  # Formula taken from https://en.wikipedia.org/wiki/Phi_coefficient\n",
    "  num = (tp*tn) - (fp*fn)\n",
    "  den = ((tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)) ** 0.5\n",
    "\n",
    "  if den != 0:\n",
    "    return num/den\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qd_99B-tUrRV"
   },
   "outputs": [],
   "source": [
    "def save(model, path_to_save: str) -> None:\n",
    "    torch.save(model.state_dict(), path_to_save)\n",
    "\n",
    "def load(model, path_to_model: str):\n",
    "    return model.load_state_dict(torch.load(path_to_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1pUh_a6PqMN"
   },
   "source": [
    "**Train and test function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0Zd_yPrEMdB"
   },
   "outputs": [],
   "source": [
    "\n",
    "# define train function (1 epoch)\n",
    "# returns average loss and accuracy\n",
    "def train(dataset, dataloader):\n",
    "\n",
    "    # switch to train mode\n",
    "    net.train()\n",
    "\n",
    "    # reset performance measures\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    # 1 epoch = 1 complete loop over the dataset\n",
    "    for batch in dataloader:\n",
    "\n",
    "        # get data from dataloader. This is the thing that I get from the get_item\n",
    "        inputs, targets = batch\n",
    "\n",
    "        # move data to device\n",
    "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # loss gradient backpropagation\n",
    "        loss.backward() # I calculate the derivatives backwards\n",
    "\n",
    "        # net parameters update\n",
    "        optimizer.step() #I use the gradients to update the weights\n",
    "\n",
    "        # accumulate loss\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        # accumulate correct outputs (for accuracy calculation)\n",
    "        outputs_max = torch.argmax(outputs, dim=1) #predicted labels\n",
    "        targets_max = targets #torch.argmax(targets, dim=1)\n",
    "        correct += outputs_max.eq(targets_max).sum().float() # this is to find out how many predictions were correct\n",
    "\n",
    "    # step learning rate scheduler\n",
    "    scheduler.step() #we just need to keep track of the steps since the LR depends on it\n",
    "\n",
    "    # return average loss and accuracy\n",
    "    return loss_sum / len(dataloader), 100. * correct / len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLRT9aFctJm9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, model_name, num_epochs=30, load_trained=False):\n",
    "    since = time.time()\n",
    "    f1 = F1Score(num_classes=2).to(device)\n",
    "\n",
    "    if load_trained:\n",
    "      checkpoint = torch.load(RESULTS_DIR + model_name)\n",
    "      model.load_state_dict(checkpoint['model_state_dict'])\n",
    "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "      last_epoch = checkpoint['epoch']+1\n",
    "      loss = checkpoint['loss']\n",
    "\n",
    "    else:\n",
    "      last_epoch=0\n",
    "\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) #It keeps track of the parameters of the model in certain state\n",
    "    best_auc = 0.0\n",
    "  \n",
    "    for epoch in range(last_epoch, num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'eval']:\n",
    "          \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "    #            running_corrects = 0\n",
    "            f1_history = list()\n",
    "\n",
    "            y_true = list()\n",
    "            y_probs = list()\n",
    "\n",
    "\n",
    "            tp_total = 0\n",
    "            fp_total = 0\n",
    "            tn_total = 0\n",
    "            fn_total = 0 \n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    probs = F.softmax(outputs, dim=1)[:,1]\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "    #                running_corrects += torch.sum(preds == labels.data)\n",
    "                f1_history.append(f1(preds, labels.data).double().cpu().numpy()) \n",
    "                y_true.append(labels.data.cpu())\n",
    "                y_probs.append(probs.cpu())\n",
    "    #                running_prerec += precision_recall(preds, labels.data)\n",
    "\n",
    "                tp, fp, tn, fn = confusion(preds, labels.data)\n",
    "                tp_total += tp\n",
    "                fp_total += fp\n",
    "                tn_total += tn\n",
    "                fn_total += fn\n",
    "    #                print(tp, fp, tn, fn) \n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_f1 = np.mean(f1_history)\n",
    "            epoch_auc = auroc(torch.cat(y_probs, dim=0), torch.cat(y_true, dim=0), max_fpr=0.0001).item()\n",
    "            epoch_mcc = mcc(tp_total, fp_total, tn_total, fn_total)\n",
    "\n",
    "            if phase == 'train':\n",
    "              scheduler.step()\n",
    "              torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                }, RESULTS_DIR+ model_name)  \n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} F1-score: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_f1))\n",
    "            print('MCC: ', epoch_mcc)\n",
    "            print('AUC: ', epoch_auc)                        \n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'eval' and epoch_auc > best_auc:\n",
    "                best_auc = epoch_auc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            del f1_history, y_true, y_probs\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val mcc: {:4f}'.format(best_auc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJteYaNJK3eZ"
   },
   "outputs": [],
   "source": [
    "# Fix the patch size\n",
    "# consider something not histogram-based\n",
    "#LBPs\n",
    "#Haar Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnYAcElltZhk"
   },
   "outputs": [],
   "source": [
    "# define test function\n",
    "# returns predictions\n",
    "def test(dataset, dataloader):\n",
    "\n",
    "    # switch to test mode\n",
    "    net.eval()  \n",
    "\n",
    "    # initialize predictions\n",
    "    predictions = []\n",
    "    reals = [] #torch.zeros(len(dataset), dtype=torch.int64)\n",
    "    sample_counter = 0\n",
    "\n",
    "    # do not accumulate gradients (faster)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # test all batches\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            # get data from dataloader [ignore labels/targets as they are not used in test mode]\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward pass\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # store predictions\n",
    "            outputs_max = torch.argmax(outputs, dim=1)\n",
    "            predictions.append( outputs_max)\n",
    "            reals.append(labels.data)\n",
    "            sample_counter += 1 #We should look for MCC, AUC or F1-score, p-AUC- Ratio of positive negatives 10 - 4, 10-3\n",
    "\n",
    "                #90 degrees rotations 1-100, 1-10\n",
    "\n",
    "                #patch wise output into a set of regions\n",
    "                #Using threshold\n",
    "                #output probability map image processing\n",
    "\n",
    "    return predictions, reals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbWX0kP4Qhrw"
   },
   "source": [
    "**Model initialization and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Emo3pdAQIPe6"
   },
   "outputs": [],
   "source": [
    "net = CNN_final(12).to(device) #we need to also send the model to the GPU as well\n",
    "\n",
    "# create loss function\n",
    "criterion = nn.CrossEntropyLoss() #most used for classification purposes\n",
    "\n",
    "# create SGD optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005) #most common optimizer is adam\n",
    "\n",
    "# create learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=lr_gamma)\n",
    "\n",
    "# experiment ID\n",
    "experiment_ID = \"%s_%s_%s_bs(%d)lr(%.4f_%d_%.1f)m(%.1f)e(%d)act(%s)xavier(yes)da(%s)do(%.1f)BN\" % (type(net).__name__, type(criterion).__name__, type(optimizer).__name__,\n",
    "                batch_size, learning_rate, lr_step_size, lr_gamma, momentum, epochs, type(activation).__name__, data_augmentation, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SugDntlJSAgh",
    "outputId": "0f3a1642-7fc7-4d83-faf0-a9a36effe486"
   },
   "outputs": [],
   "source": [
    "model = train_model(net, criterion, optimizer, scheduler, '/model_12_5.pt', num_epochs=epochs, load_trained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rf_vzbUBZA-P"
   },
   "outputs": [],
   "source": [
    "save(model, RESULTS_DIR+'/model_try1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFBKnnwrTgaU"
   },
   "source": [
    "## **Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ji-9niw54kh"
   },
   "outputs": [],
   "source": [
    "del dataset_train\n",
    "del dataset_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ww11T0595xhv",
    "outputId": "7cbfba0f-5a7d-46f9-d21e-1b0e7ba82a79"
   },
   "outputs": [],
   "source": [
    "import roi_cc_project\n",
    "\n",
    "dataset_test = roi_cc_project.CvROI([noMC_file_test, MC_file_test], os.path.join(DATA_DIR, 'images'), img_prefix='', img_suffix='', img_channel=None, img_list='', train=False,\n",
    "                 crossvalid=(1, 1), class_weights=None, class_max_counts=None, class_min_counts=None,\n",
    "                 preprocessing=None, augmentation=None, verbose=True)\n",
    "# dataset = roi_cc_project.UnlabeledImageROI(os.path.join(DATA_DIR, 'images', '20586908_6c613a14b80a8591_MG_R_CC_ANON.tif'),os.path.join(DATA_DIR, 'groundtruths', '20586908_6c613a14b80a8591_MG_R_CC_ANON.tif'), (12,12), img_channel=None, preprocessing=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Sam8tBr7Q1a"
   },
   "outputs": [],
   "source": [
    "# Add weights to the Cross Entropy Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pGR-Sur6NSm"
   },
   "outputs": [],
   "source": [
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "Wy_vO9jx5cl9",
    "outputId": "47ce7cc0-4076-43d9-a848-540617d6f84c"
   },
   "outputs": [],
   "source": [
    "predictions, reals = test(dataset_test, dataloader_test)\n",
    "accuracy = 100. * predictions.eq(reals).sum().float() / len(dataset_test)\n",
    "print (\"Accuracy on test set is %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxwqD-PASnmX"
   },
   "source": [
    "# **Chaos zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKRXEiPl-8Pr"
   },
   "outputs": [],
   "source": [
    "net = CNN1().to(device) #we need to also send the model to the GPU as well\n",
    "\n",
    "# create loss function\n",
    "criterion = nn.CrossEntropyLoss() #most used for classification purposes\n",
    "\n",
    "# create SGD optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum) #most common optimizer is adam\n",
    "\n",
    "# create learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
    "\n",
    "# experiment ID\n",
    "experiment_ID = \"%s_%s_%s_bs(%d)lr(%.4f_%d_%.1f)m(%.1f)e(%d)act(%s)xavier(yes)da(%s)do(%.1f)BN\" % (type(net).__name__, type(criterion).__name__, type(optimizer).__name__,\n",
    "                batch_size, learning_rate, lr_step_size, lr_gamma, momentum, epochs, type(activation).__name__, data_augmentation, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "x93afF_e9ck7",
    "outputId": "b52c445b-9536-4b58-b58a-39d7b628e277"
   },
   "outputs": [],
   "source": [
    "model = train_model(net, criterion, optimizer, scheduler, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7ZeLnjY0O7L"
   },
   "outputs": [],
   "source": [
    "class CNN2_mod(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "      super(CNN2_mod, self).__init__()\n",
    "\n",
    "      # in_channels is number of channels (this is because we have a patch of 1 image)\n",
    "      # out_channels is number of filters or kernels given out by the convolution\n",
    "      # stride is a parameter (default is 1)\n",
    "      self.conv1 =  nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "      self.bn1 = nn.BatchNorm2d(64)\n",
    "      self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "      self.bn2 = nn.BatchNorm2d(64)\n",
    "      self.pool1 = nn.MaxPool2d(kernel_size=2, padding=1)\n",
    "      self.dropout1=nn.Dropout(p=0.2)\n",
    "      self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "      self.flatten = nn.Flatten()\n",
    "\n",
    "      self.fc1 = nn.Linear(3136,2)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "\n",
    "      nn.init.xavier_normal_(self.conv1.weight)\n",
    "      nn.init.xavier_normal_(self.conv2.weight)\n",
    "\n",
    "      nn.init.xavier_normal_(self.fc1.weight)\n",
    "      nn.init.xavier_normal_(self.fc2.weight)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "      x = self.conv1(x)\n",
    "#      x = self.conv2(x)\n",
    "      x = self.pool1(x)\n",
    "      x = self.dropout1(x)\n",
    "      x = self.flatten(x)\n",
    "      x = self.fc1(x)\n",
    "      # x = activation(x)\n",
    "      # x = self.fc2(x)\n",
    "\n",
    "      return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9U_U2vWGIelT",
    "outputId": "9e695278-316b-4a27-985c-8d556023cda4"
   },
   "outputs": [],
   "source": [
    "net = CNN2_mod()\n",
    "# summary(net, (1,12,12))\n",
    "\n",
    "dummy_variable = torch.rand(1,1,12,12) #batch size, channel, image size\n",
    "net(dummy_variable).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvkjM0xc2APS"
   },
   "outputs": [],
   "source": [
    "net = CNN2_mod().to(device) #we need to also send the model to the GPU as well\n",
    "\n",
    "# create loss function\n",
    "criterion = nn.CrossEntropyLoss() #most used for classification purposes\n",
    "\n",
    "# create SGD optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=momentum) #most common optimizer is adam\n",
    "\n",
    "# create learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=0.1)\n",
    "\n",
    "# experiment ID\n",
    "experiment_ID = \"%s_%s_%s_bs(%d)lr(%.4f_%d_%.1f)m(%.1f)e(%d)act(%s)xavier(yes)da(%s)do(%.1f)BN\" % (type(net).__name__, type(criterion).__name__, type(optimizer).__name__,\n",
    "                batch_size, learning_rate, lr_step_size, lr_gamma, momentum, epochs, type(activation).__name__, data_augmentation, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "sBXPTUVi2Dqn",
    "outputId": "00fbbab0-e646-4c08-e2f5-0c186899927a"
   },
   "outputs": [],
   "source": [
    "model = train_model(net, criterion, optimizer, scheduler, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6Xmx6L36K7T"
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i in range(len(predictions)):\n",
    "  acc += predictions[i].eq(reals[i]).sum().float()\n",
    "accuracy = 100*acc/len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-Sxx2HOEoJe"
   },
   "outputs": [],
   "source": [
    "f1_score = 0\n",
    "f1 = F1Score(num_classes=2).to(device)\n",
    "\n",
    "for i in range(len(predictions)):  \n",
    "  f1_score += f1(predictions[i], reals[i]).double()\n",
    "\n",
    "f1_score2 = 100*f1_score/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3O6y8me8ENF_",
    "outputId": "6387aabc-9ff8-483c-8197-8d73d4ed80f8"
   },
   "outputs": [],
   "source": [
    "f1_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "0jQMSj59ZRuX",
    "outputId": "049f0953-7e79-4662-9ae7-bb292c7d8f1d"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # mean = np.array([0.485, 0.456, 0.406])\n",
    "    # std = np.array([0.229, 0.224, 0.225])\n",
    "    # inp = std * inp + mean\n",
    "    # inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "# inputs, classes = next(iter(loader.rois[0]))\n",
    "\n",
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfjBGhBEaSoh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "DeepLearning_MC_project_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
