{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c2bdab",
   "metadata": {},
   "source": [
    "### GENERATING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46964cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import library\n",
    "import color_features\n",
    "import texture_features\n",
    "import glcm_features\n",
    "import hair_removal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "samples = library.get_sample(path = \"/home/name/Desktop/CAD/challenge1/train\", amount=3000)\n",
    "\n",
    "dictF = {}\n",
    "features = pd.DataFrame()\n",
    "count = 0\n",
    "flag = True\n",
    "for sample in samples:\n",
    "    print('count ', count)\n",
    "    count += 1\n",
    "    img = cv2.imread(sample)\n",
    "    output_bh = library.hair_removal_BH(img)\n",
    "    \n",
    "    dictF['name'] = sample\n",
    "    dictF['label'] = (0 if 'nevus' in sample else 1 )\n",
    "    \n",
    "    # color features\n",
    "    colors = color_features.extract_color_features(output_bh)\n",
    "    \n",
    "    dictF.update(colors)\n",
    "    \n",
    "    #glcm features\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    distances = [1]\n",
    "    colorspaces = ['rgb', 'hsv', 'lab', 'ycc', 'gray']\n",
    "\n",
    "    for cs in colorspaces:\n",
    "        glcm = glcm_features.get_glcm(output_bh, angles, distances, cs)\n",
    "        dictF.update(glcm)\n",
    "    \n",
    "    # lbp features\n",
    "    lbp = texture_features.extract_lbp(output_bh, 1, 8)\n",
    "    dictF.update(lbp)\n",
    "    \n",
    "    # orb features\n",
    "    # orb = texture_features.extract_orb(output_bh, 64)\n",
    "    # dictF.update(orb)\n",
    "    \n",
    "    features = features.append(dictF, ignore_index=True)\n",
    "    \n",
    "    library.writeFeatures(features,\n",
    "                  flag,\n",
    "                  os.path.join('/home',\n",
    "                             'name',\n",
    "                             'Desktop',\n",
    "                             'CAD'),\n",
    "                  'features_train_bh_3000.csv')\n",
    "    \n",
    "    flag = False\n",
    "    features = pd.DataFrame()\n",
    "    dictF.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import library\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import os\n",
    "    \n",
    "\n",
    "classifiers = [\"rf\", \"tree\", \"svm\", \"adaboost\", \"gradboost\", \"knn\"]\n",
    "\n",
    "train = pd.read_csv(os.path.join('/home','emily','Desktop','CAD','features_briashaver_colors_glcm_854.csv'))\n",
    "\n",
    "y = train['label']\n",
    "X = train.drop(['label'], axis=1)\n",
    "X = X.drop(['name'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "print(\"x_test \", len(X_test))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "for classifier in classifiers:\n",
    "    \n",
    "    if classifier == \"svm\":\n",
    "        clf, best_params = library.SVC_linear(X_val, y_val, cv=2)\n",
    "        clf.set_params(**best_params) \n",
    "        print(\"### SVM ###\")\n",
    "        library.fit_report(clf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    elif classifier == \"rf\":\n",
    "        clf, best_params = library.RandomForest(X_val, y_val, cv=2)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### RF ###\")\n",
    "        library.fit_report(clf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    elif classifier == \"tree\":\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "        print(\"### TREE ###\")\n",
    "        library.fit_report(clf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    elif classifier == \"adaboost\":\n",
    "        clf, best_params = library.AdaBoost(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### ADABOOST ###\")\n",
    "        library.fit_report(clf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    elif classifier == \"gradboost\":\n",
    "        clf, best_params = library.GradientBoosting(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### GRADBOOST ###\")\n",
    "        library.fit_report(clf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    elif classifier == \"knn\":\n",
    "        clf, best_params = library.knn(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### KNN ###\")\n",
    "        library.fit_report(clf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    #elif classifier == \"ensemble\": \n",
    "        #ensemble\n",
    "        #best_paramsSVM = gridSearchSVM(hyperOptTrainData, hyperOptLabel, cv)\n",
    "        # best_paramsRF = gridSearchRF(hyperOptTrainData, hyperOptLabel, cv) 0.18-0.20\n",
    "        #best_paramsGB = gridSearchGradientBoosting(hyperOptTrainData, hyperOptLabel, cv)\n",
    "        #best_paramsAB = gridSearchAdaBoost(hyperOptTrainData, hyperOptLabel, cv)# 0.16-0.19 lr=0.1\n",
    "        #best_paramsLR = gridSearchLogRegre(hyperOptTrainData, hyperOptLabel, cv)\n",
    "\n",
    "        #pipeSVC = Pipeline([('scaler', StandardScaler()), ('svm', SVC(**best_paramsSVM, probability=True))])# false -> class\n",
    "        # pipeRF  = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier( **best_paramsRF,  n_jobs = -1, random_state=42))])\n",
    "        #pipeAB  = Pipeline([('scaler', StandardScaler()), ('ab', AdaBoostClassifier( **best_paramsAB, random_state=42))]) \n",
    "        #pipeGB  = Pipeline([('scaler', StandardScaler()), ('gb', GradientBoostingClassifier( **best_paramsGB, random_state=42))])\n",
    "        #pipeLR = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(**best_paramsLR, random_state=42))]) \n",
    "        #pipeNB = Pipeline([('scaler', StandardScaler()), ('nb', GaussianNB())])\n",
    "\n",
    "        #clf = VotingClassifier(estimators=[('svm', pipeSVC),\n",
    "        #                                   ('lr', pipeLR),\n",
    "        #                                   ('ab', pipeAB),\n",
    "        #                                   ('gb', pipeGB),\n",
    "        #                                   ('nb', pipeNB)],\n",
    "        #                                   voting = 'soft')\n",
    "\n",
    "        #fit_report(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ab1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0a688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0d95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
