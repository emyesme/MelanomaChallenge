{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip setuptools wheel\n",
    "#!python -m pip install opencv-python\n",
    "#!pip install matplotlib\n",
    "#!pip freeze\n",
    "#!pip install opencv-python-headless\n",
    "#!pip install scikit-image\n",
    "#!pip install -U scikit-fuzzy\n",
    "#!pip install pandas\n",
    "#!pip install scikit-learn\n",
    "#!pip install tqdm==4.40.0\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from skimage import measure\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "import skfuzzy as fuzz\n",
    "import library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import library\n",
    "import texture_features\n",
    "import color_features\n",
    "import glcm_features\n",
    "import hair_removal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "flag = True\n",
    "\n",
    "output = os.path.join('/home',\n",
    "                     'emily',\n",
    "                     'Desktop',\n",
    "                     'CAD',\n",
    "                     'MelanomaChallenge',\n",
    "                     'features',\n",
    "                     'featuresCh1E.csv')\n",
    "\n",
    "\n",
    "\n",
    "samples, flag = library.get_sample(\"/home/emily/Desktop/CAD/challenge2/train\", output, flag)\n",
    "print(len(samples))\n",
    "\n",
    "dictF = {}\n",
    "\n",
    "features = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for sample in samples:\n",
    "    #print('count ', count)\n",
    "    count += 1\n",
    "    \n",
    "    # read image\n",
    "    img = cv2.imread(sample)\n",
    "    \n",
    "    # clahe preprocessing\n",
    "    #clahe = library.clahe_rgb(img, 8)\n",
    "    \n",
    "    # gray world. color balanced\n",
    "    #grey_world = library.grey_world(clahe)\n",
    "    \n",
    "    # hair removal\n",
    "    clahe = clahe.astype(\"uint8\")\n",
    "    hairless = hair_removal.hair_remove(img, 17, 4)\n",
    "    \n",
    "    # save name\n",
    "    dictF['name'] = sample\n",
    "    # label\n",
    "    if 'bcc' in sample:\n",
    "        dictF['label'] = 1\n",
    "    elif 'mel' in sample:\n",
    "        dictF['label'] = 0\n",
    "    elif 'scc' in sample:\n",
    "        dictF['label'] = 2\n",
    "    \n",
    "    # color features\n",
    "    colors = color_features.extract_color_features(hairless)\n",
    "    dictF.update(colors)\n",
    "    \n",
    "    # glcm features\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    distances = [1]\n",
    "    colorspaces = ['rgb', 'hsv', 'lab', 'ycc', 'gray']\n",
    "    \n",
    "    for cs in colorspaces:\n",
    "        glcm = glcm_features.get_glcm(hairless, angles, distances, cs)\n",
    "        dictF.update(glcm)\n",
    "    \n",
    "    \n",
    "    # lbp features\n",
    "    lbp = texture_features.extract_lbp(hairless, 1, 8)\n",
    "    dictF.update(lbp)\n",
    "    \n",
    "    # orb features\n",
    "    #hairless = cv2.cvtColor(hairless, cv2.COLOR_BGR2RGB)\n",
    "    #hairless = np.uint16(hairless)\n",
    "    #orb = texture_features.extract_orb(hairless, 64)\n",
    "    #dictF.update(orb)\n",
    "    \n",
    "    features = features.append(dictF, ignore_index=True)\n",
    "    \n",
    "    # save features\n",
    "    library.writeFeatures(features,\n",
    "                  flag,\n",
    "                  os.path.join('/home',\n",
    "                             'emily',\n",
    "                             'Desktop',\n",
    "                             'CAD',\n",
    "                             'MelanomaChallenge',\n",
    "                             'features'),\n",
    "                             'featuresCh2TrainB.csv')\n",
    "    \n",
    "    \n",
    "    flag = False\n",
    "    features = pd.DataFrame()\n",
    "    dictF.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import library\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif    \n",
    "\n",
    "#\n",
    "classifiers = [\"rf\", \"tree\", \"svm\", \"adaboost\", \"gradboost\", \"histgradboost\", \"knn\", \"lda\"]\n",
    "\n",
    "train = pd.read_csv(os.path.join('/home','emily','Desktop','CAD','MelanomaChallenge','features','features_train_bh_3000.csv'))\n",
    "test = pd.read_csv(os.path.join('/home','emily','Desktop','CAD','MelanomaChallenge','features','features_test_bh_3000.csv'))\n",
    "\n",
    "y = train['label']\n",
    "X = train.drop(['label'], axis=1)\n",
    "X = X.drop(['name'], axis=1)\n",
    "\n",
    "\n",
    "y_test = test['label']\n",
    "X_test = test.drop(['label'], axis=1)\n",
    "X_test = X_test.drop(['name'], axis=1)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=1)\n",
    "\n",
    "# preprocessing options\n",
    "#('selectFromModel', SelectFromModel(RandomForestClassifier(random_state=42, n_jobs = -1)))\n",
    "#('selector rfe', RFE(RandomForestClassifier(random_state=42, n_jobs = -1))),\n",
    "#('reduce_dims', PCA(n_components=150)),\n",
    "#('mutual_info_classif, SelectKBest(mutual_info_classif, k=100)),\n",
    "\n",
    "for classifier in classifiers:\n",
    "    \n",
    "    # preprocessing steps\n",
    "    pipe = [('scale', StandardScaler()),\n",
    "            ('selector rfe', RFE(RandomForestClassifier(random_state=42, n_jobs = -1)))\n",
    "           ]\n",
    "\n",
    "    \n",
    "    if classifier == \"svm\":\n",
    "        clf, best_params = library.SVC_linear(X_val, y_val, cv=2)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### SVM ###\")\n",
    "    \n",
    "    elif classifier == \"rf\":\n",
    "        clf, best_params = library.RandomForest(X_val, y_val, cv=2)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### RF ###\")\n",
    "    \n",
    "    elif classifier == \"tree\":\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "        print(\"### TREE ###\")\n",
    "    \n",
    "    elif classifier == \"adaboost\":\n",
    "        clf, best_params = library.AdaBoost(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### ADABOOST ###\")\n",
    "    \n",
    "    elif classifier == \"gradboost\":\n",
    "        clf, best_params = library.GradientBoosting(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### GRADBOOST ###\")\n",
    "    \n",
    "    elif classifier == \"knn\":\n",
    "        clf, best_params = library.knn(X_val, y_val)\n",
    "        clf.set_params(**best_params)\n",
    "        print(\"### KNN ###\")\n",
    "        \n",
    "    elif classifier == \"histgradboost\":\n",
    "        clf = HistGradientBoostingClassifier()\n",
    "        print(\"### HISTGRADBOOST ###\")\n",
    "        \n",
    "    elif classifier == \"lda\":\n",
    "        clf = LinearDiscriminantAnalysis()\n",
    "        print(\"### LDA ###\")        \n",
    "        \n",
    "    # add classifier \n",
    "    pipe.append(tuple(('clf', clf)))\n",
    "    \n",
    "    steps = Pipeline(pipe)\n",
    "    \n",
    "    # pipeline shape\n",
    "    print(\"current pipeline\")\n",
    "    print(steps)\n",
    "    \n",
    "    library.fit_report(steps, X, y, X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8303346cf061856616ea71480663e8efb94f012cfcc13615ad12237b3e78185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
